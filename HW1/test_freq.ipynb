{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 15:19:52 INFO     Loading dataset\n"
     ]
    }
   ],
   "source": [
    "import datasets as ds\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import logging\n",
    "import itertools\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "logging.info(\"Loading dataset\")\n",
    "\n",
    "# dataset = ds.load_dataset(\"ag_news\")\n",
    "# dataset.save_to_disk(\"/home/magraz/AI539_NLP/HW1/data\")\n",
    "\n",
    "dataset = ds.load_from_disk(\"/home/magraz/AI539_NLP/HW1/data/ag_news\")\n",
    "\n",
    "dataset_text =  [r['text'] for r in dataset['train']]\n",
    "dataset_labels = [r['label'] for r in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 15:19:56 INFO     Building vocabulary\n",
      "2024-04-17 15:20:09 INFO     [\"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\"]\n",
      "2024-04-17 15:20:09 INFO     6274\n",
      "2024-04-17 15:20:09 INFO     {0: 'the', 1: 'to', 2: 'of', 3: 'in', 4: 'and', 5: 'on', 6: 'for', 7: 'it', 8: 'that', 9: 'with', 10: 'a', 11: 'at', 12: 'is', 13: 'new', 14: 'by', 15: 'said', 16: 'reuters', 17: 'ha', 18: 'from', 19: 'an', 20: 'ap', 21: 'his', 22: 'will', 23: 'after', 24: 'year', 25: 'wa', 26: 'gt', 27: 'u', 28: 'lt', 29: 'be', 30: 'over', 31: 'have', 32: 'up', 33: 'their', 34: 'two', 35: 'company', 36: 'first', 37: 'are', 38: 'quot', 39: 'but', 40: 'more', 41: 'he', 42: 'world', 43: 'one', 44: 'this', 45: 'game', 46: 'say', 47: 'monday', 48: 'out', 49: 'oil', 50: 'wednesday', 51: 'tuesday', 52: 'thursday', 53: 'week', 54: 'not', 55: 'stock', 56: 'state', 57: 'against', 58: 'friday', 59: 'inc', 60: 'than', 61: 'price', 62: 'into', 63: 'time', 64: 'last', 65: 'they', 66: 'about', 67: 'iraq', 68: 'million', 69: 'york', 70: 'day', 71: 'yesterday', 72: 'who', 73: 'president', 74: 'three', 75: 'no', 76: 'microsoft', 77: 'were', 78: 'win', 79: 'been', 80: 'plan', 81: 'security', 82: 'group', 83: 'service', 84: 'had', 85: 'corp', 86: 'official', 87: 'united', 88: 'government', 89: 'team', 90: 'month', 91: 'when', 92: 'com', 93: 'sunday', 94: 'report', 95: 'second', 96: 'back', 97: 'could', 98: 'would', 99: 'today'}\n",
      "2024-04-17 15:20:09 INFO     {'the': 205464, 'to': 120746, 'of': 98649, 'in': 96442, 'and': 69672, 'on': 57664, 'for': 50672, 'it': 42657, 'that': 28169, 'with': 26810, 'a': 25377, 'at': 25066, 'is': 22098, 'new': 21421, 'by': 20942, 'said': 20266, 'reuters': 19339, 'ha': 19051, 'from': 17825, 'an': 17002, 'ap': 16276, 'his': 14942, 'will': 14635, 'after': 14549, 'year': 14486, 'wa': 13747, 'gt': 13231, 'u': 13220, 'lt': 13182, 'be': 11834, 'over': 11377, 'have': 11216, 'up': 10736, 'their': 10530, 'two': 10226, 'company': 10170, 'first': 9811, 'are': 9792, 'quot': 9596, 'but': 9184, 'more': 9149, 'he': 8962, 'world': 8830, 'one': 8253, 'this': 8250, 'game': 8177, 'say': 7684, 'monday': 7624, 'out': 7608, 'oil': 7562, 'wednesday': 7538, 'tuesday': 7464, 'thursday': 7347, 'week': 7169, 'not': 7063, 'stock': 6938, 'state': 6928, 'against': 6900, 'friday': 6878, 'inc': 6853, 'than': 6733, 'price': 6711, 'into': 6676, 'time': 6583, 'last': 6552, 'they': 6453, 'about': 6428, 'iraq': 6374, 'million': 6321, 'york': 6274, 'day': 6171, 'yesterday': 6118, 'who': 6090, 'president': 6054, 'three': 6036, 'no': 5951, 'microsoft': 5924, 'were': 5811, 'win': 5738, 'been': 5534, 'plan': 5485, 'security': 5435, 'group': 5358, 'service': 5347, 'had': 5279, 'corp': 5216, 'official': 5180, 'united': 5122, 'government': 5115, 'team': 5115, 'month': 5037, 'when': 5025, 'com': 4966, 'sunday': 4959, 'report': 4958, 'second': 4912, 'back': 4862, 'could': 4854, 'would': 4821, 'today': 4729}\n",
      "2024-04-17 15:20:09 INFO     Computing PPMI matrix\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     16\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing PPMI matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# C = compute_cooccurrence_matrix(dataset_text[:window], vocab)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# logging.info(C)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m PPMI \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ppmi_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# # logging.info(PPMI)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerforming Truncated SVD to reduce dimensionality\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/AI539_NLP/HW1/build_freq_vectors.py:86\u001b[0m, in \u001b[0;36mcompute_ppmi_matrix\u001b[0;34m(corpus, vocab)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_ppmi_matrix\u001b[39m(corpus, vocab):\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m\t    \u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\t    compute_ppmi_matrix takes in list of strings corresponding to a text corpus and a vocabulary of size N and returns \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\t    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \tC \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_cooccurrence_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n\u001b[1;32m     88\u001b[0m \tPPMI \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((vocab\u001b[38;5;241m.\u001b[39msize, vocab\u001b[38;5;241m.\u001b[39msize))\n\u001b[1;32m     90\u001b[0m \tN \u001b[38;5;241m=\u001b[39m vocab\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m~/AI539_NLP/HW1/build_freq_vectors.py:48\u001b[0m, in \u001b[0;36mcompute_cooccurrence_matrix\u001b[0;34m(corpus, vocab)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#Co-ocurrence matrix\u001b[39;00m\n\u001b[1;32m     46\u001b[0m C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((vocab\u001b[38;5;241m.\u001b[39msize, vocab\u001b[38;5;241m.\u001b[39msize))\n\u001b[0;32m---> 48\u001b[0m corpus_idx \u001b[38;5;241m=\u001b[39m \u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext2idx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, center \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(corpus_idx):\n\u001b[1;32m     51\u001b[0m \n\u001b[1;32m     52\u001b[0m \t\u001b[38;5;66;03m# if (i % k_wind) == 0:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m-\u001b[39m k_wind) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m :\n",
      "File \u001b[0;32m~/AI539_NLP/HW1/Vocabulary.py:25\u001b[0m, in \u001b[0;36mVocabulary.text2idx\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtext2idx\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m---> 25\u001b[0m \ttokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2idx[t] \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2idx\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword2idx[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNK\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens]\n",
      "File \u001b[0;32m~/AI539_NLP/HW1/Vocabulary.py:62\u001b[0m, in \u001b[0;36mVocabulary.tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     59\u001b[0m \ttext_str \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m row \n\u001b[1;32m     61\u001b[0m text_str \u001b[38;5;241m=\u001b[39m text_str\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(string\u001b[38;5;241m.\u001b[39mpunctuation, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(string\u001b[38;5;241m.\u001b[39mpunctuation)))\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m---> 62\u001b[0m tokenized_text \u001b[38;5;241m=\u001b[39m [w \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m text_str\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(w)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m w\u001b[38;5;241m.\u001b[39misnumeric())]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#Lemmatize\u001b[39;00m\n\u001b[1;32m     65\u001b[0m tokenized_text \u001b[38;5;241m=\u001b[39m [lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(token) \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m tokenized_text]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Vocabulary import Vocabulary\n",
    "from build_freq_vectors import compute_cooccurrence_matrix, compute_ppmi_matrix, dim_reduce, plot_word_vectors_tsne\n",
    "\n",
    "logging.info(\"Building vocabulary\")\n",
    "\n",
    "vocab = Vocabulary(dataset_text)\n",
    "\n",
    "logging.info(dataset_text[:1])\n",
    "# logging.info(vocab.word2idx)\n",
    "logging.info(len(list(vocab.word2idx.keys())))\n",
    "logging.info(dict(list(vocab.idx2word.items())[:100]))\n",
    "logging.info(dict(list(vocab.freq.items())[:100]))\n",
    "\n",
    "# vocab.make_vocab_charts()\n",
    "\n",
    "logging.info(\"Computing PPMI matrix\")\n",
    "# C = compute_cooccurrence_matrix(dataset_text[:window], vocab)\n",
    "# logging.info(C)\n",
    "\n",
    "PPMI = compute_ppmi_matrix(dataset_text, vocab)\n",
    "# # logging.info(PPMI)\n",
    "\n",
    "logging.info(\"Performing Truncated SVD to reduce dimensionality\")\n",
    "word_vectors = dim_reduce(PPMI)\n",
    "# # logging.info(word_vectors)\n",
    "\n",
    "\n",
    "logging.info(\"Preparing T-SNE plot\")\n",
    "plot_word_vectors_tsne(word_vectors, vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI539_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
